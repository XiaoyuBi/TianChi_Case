{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  #线性回归\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor  #K近邻回归\n",
    "from sklearn.tree import DecisionTreeRegressor     #决策树回归\n",
    "from sklearn.ensemble import RandomForestRegressor #随机森林回归\n",
    "from sklearn.svm import SVR  #支持向量回归\n",
    "import lightgbm as lgb #lightGbm模型\n",
    "\n",
    "from sklearn.model_selection import train_test_split # 切分数据\n",
    "from sklearn.metrics import mean_squared_error #评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"data/zhengqi_train.txt\"\n",
    "test_data_file =  \"data/zhengqi_test.txt\"\n",
    "\n",
    "train_data = pd.read_csv(train_data_file, sep = '\\t', encoding = 'utf-8')\n",
    "test_data = pd.read_csv(test_data_file, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理\n",
    "from sklearn import preprocessing\n",
    "\n",
    "features_columns = [col for col in train_data.columns if col not in ['target']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "min_max_scaler  = min_max_scaler.fit(train_data[features_columns])\n",
    "train_data_scaler = min_max_scaler.transform(train_data[features_columns])\n",
    "test_data_scaler = min_max_scaler.transform(test_data[features_columns])\n",
    "\n",
    "train_data_scaler = pd.DataFrame(train_data_scaler)\n",
    "train_data_scaler.columns = features_columns\n",
    "test_data_scaler = pd.DataFrame(test_data_scaler)\n",
    "test_data_scaler.columns = features_columns\n",
    "train_data_scaler['target'] = train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA降维\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 保留16个主成分\n",
    "pca = PCA(n_components = 16)\n",
    "new_train_pca_16 = pca.fit_transform(train_data_scaler.iloc[:, 0:-1])\n",
    "new_test_pca_16 = pca.transform(test_data_scaler)\n",
    "new_train_pca_16 = pd.DataFrame(new_train_pca_16)\n",
    "new_test_pca_16 = pd.DataFrame(new_test_pca_16)\n",
    "new_train_pca_16['target'] = train_data_scaler['target']\n",
    "\n",
    "new_train_pca_16 = new_train_pca_16.fillna(0)\n",
    "train = new_train_pca_16[new_test_pca_16.columns]\n",
    "target = new_train_pca_16['target']\n",
    "test = test_data_scaler\n",
    "\n",
    "# 划分验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "source": [
    "## 欠拟合"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SGDRegressor train MSE:    0.1515726845129755\nSGDRegressor val MSE:    0.15586174356637902\n"
     ]
    }
   ],
   "source": [
    "clf = SGDRegressor(max_iter = 500, tol = 1e-2)\n",
    "clf.fit(X_train, y_train)\n",
    "score_train = mean_squared_error(y_train, clf.predict(X_train))\n",
    "score_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor val MSE:   \", score_val)"
   ]
  },
  {
   "source": [
    "## 过拟合/正常拟合"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SGDRegressor train MSE:    0.13238208914548613\nSGDRegressor val MSE:    0.14297697760646055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(4)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly = poly.transform(X_val)\n",
    "clf = SGDRegressor(max_iter = 1000, tol = 1e-3)\n",
    "clf.fit(X_train_poly, y_train)\n",
    "score_train = mean_squared_error(y_train, clf.predict(X_train_poly))\n",
    "score_val = mean_squared_error(y_val, clf.predict(X_val_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor val MSE:   \", score_val)"
   ]
  },
  {
   "source": [
    "## 模型正则化"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SGDRegressor train MSE:    0.13432411873987127\nSGDRegressor test MSE:    0.14280502868587774\n"
     ]
    }
   ],
   "source": [
    "# L2正则化\n",
    "poly = PolynomialFeatures(3)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly =poly.transform(X_val)\n",
    "clf = SGDRegressor(max_iter = 1000, tol = 1e-3, penalty = 'l2', alpha = 0.0001)\n",
    "clf.fit(X_train_poly, y_train)\n",
    "score_train = mean_squared_error(y_train, clf.predict(X_train_poly))\n",
    "score_val = mean_squared_error(y_val, clf.predict(X_val_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SGDRegressor train MSE:    0.13434456290733987\nSGDRegressor test MSE:    0.14256865012598008\n"
     ]
    }
   ],
   "source": [
    "# L1正则化\n",
    "poly = PolynomialFeatures(3)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly =poly.transform(X_val)\n",
    "clf = SGDRegressor(max_iter = 1000, tol = 1e-3, penalty = 'l1', alpha = 0.00001)\n",
    "clf.fit(X_train_poly, y_train)\n",
    "score_train = mean_squared_error(y_train, clf.predict(X_train_poly))\n",
    "score_val = mean_squared_error(y_val, clf.predict(X_val_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SGDRegressor train MSE:    0.13429286643201233\nSGDRegressor test MSE:    0.14224556452390136\n"
     ]
    }
   ],
   "source": [
    "# Elastic Net L1和L2范数加权正则化\n",
    "poly = PolynomialFeatures(3)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly =poly.transform(X_val)\n",
    "clf = SGDRegressor(max_iter = 1000, tol = 1e-3, penalty = 'elasticnet', l1_ratio = 0.9, alpha = 0.00001)\n",
    "clf.fit(X_train_poly, y_train)\n",
    "score_train = mean_squared_error(y_train, clf.predict(X_train_poly))\n",
    "score_val = mean_squared_error(y_val, clf.predict(X_val_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_val)"
   ]
  },
  {
   "source": [
    "## 模型交叉验证"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单交叉验证\n",
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0  折 SGDRegressor train MSE:    0.15000356251049293\n0  折 SGDRegressor test MSE:    0.10622087416418229 \n\n1  折 SGDRegressor train MSE:    0.13364067803379637\n1  折 SGDRegressor test MSE:    0.1823658908030779 \n\n2  折 SGDRegressor train MSE:    0.14722005039466307\n2  折 SGDRegressor test MSE:    0.1334506106367118 \n\n3  折 SGDRegressor train MSE:    0.14065476442376965\n3  折 SGDRegressor test MSE:    0.1618515108030737 \n\n4  折 SGDRegressor train MSE:    0.1388734233363064\n4  折 SGDRegressor test MSE:    0.1654348638354631 \n\n"
     ]
    }
   ],
   "source": [
    "# K折交叉验证\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "for k, (train_index, val_index) in enumerate(kf.split(train)):\n",
    "    X_train, X_val = train.values[train_index], train.values[val_index]\n",
    "    y_train, y_val = target[train_index], target[val_index]\n",
    "    clf = SGDRegressor(max_iter = 1000, tol = 1e-3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score_train = mean_squared_error(y_train, clf.predict(X_train))\n",
    "    score_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "    print(k, \" 折\", \"SGDRegressor train MSE:   \", score_train)\n",
    "    print(k, \" 折\", \"SGDRegressor test MSE:   \", score_val, '\\n') "
   ]
  },
  {
   "source": [
    "## 模型超参空间及调参"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RandomForestRegressor GridSearchCV test MSE:  0.2569545475330938\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_depth',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "rfRegressor = RandomForestRegressor()\n",
    "parameters = {\n",
    "    'n_estimators':[50, 100, 200],\n",
    "    'max_depth':[1, 2, 3],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(rfRegressor, parameters, cv = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "score_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "\n",
    "print('RandomForestRegressor GridSearchCV test MSE: ', score_val)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RandomForestRegressor RandomizedSearchCV test MSE:  0.19751458490309642\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_depth',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "#随机参数优化\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "rfRegressor = RandomForestRegressor()\n",
    "parameters = {\n",
    "    'n_estimators':[50, 100, 200, 300],\n",
    "    'max_depth':[1, 2, 3, 4, 5],\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(rfRegressor, parameters, cv = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "score_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "\n",
    "print('RandomForestRegressor RandomizedSearchCV test MSE: ', score_val)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found by random search are: {'n_estimators': 40, 'learning_rate': 0.1}\nLGBMRegressor RandomizedSearchCV test MSE:    0.1518395195375679\n"
     ]
    }
   ],
   "source": [
    "# LGB调参\n",
    "clf = lgb.LGBMRegressor(num_leaves = 31)\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate':[0.01, 0.1, 1],\n",
    "    'n_estimators': [20, 40],\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(clf, parameters, cv = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters found by random search are:', clf.best_params_)\n",
    "score_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "print(\"LGBMRegressor RandomizedSearchCV test MSE:   \", score_val)"
   ]
  },
  {
   "source": [
    "## LGB线下验证"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[600]\tTrain's l2: 0.0885543\tTest's l2: 0.14705\n",
      "[1200]\tTrain's l2: 0.065332\tTest's l2: 0.137558\n",
      "Early stopping, best iteration is:\n",
      "[1648]\tTrain's l2: 0.0551673\tTest's l2: 0.135952\n",
      "\n",
      "第0折 训练和预测 训练MSE 预测MSE\n",
      "------\t 训练MSE\t 0.05516727388413645 \t------\n",
      "------\t 预测MSE\t 0.1359523071002833 \t------\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[600]\tTrain's l2: 0.090066\tTest's l2: 0.144457\n",
      "[1200]\tTrain's l2: 0.0663808\tTest's l2: 0.133415\n",
      "[1800]\tTrain's l2: 0.0523241\tTest's l2: 0.131299\n",
      "Early stopping, best iteration is:\n",
      "[1778]\tTrain's l2: 0.0528158\tTest's l2: 0.131152\n",
      "\n",
      "第1折 训练和预测 训练MSE 预测MSE\n",
      "------\t 训练MSE\t 0.0528157973823114 \t------\n",
      "------\t 预测MSE\t 0.13115224061373387 \t------\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[600]\tTrain's l2: 0.0904795\tTest's l2: 0.126143\n",
      "[1200]\tTrain's l2: 0.0663034\tTest's l2: 0.118513\n",
      "Early stopping, best iteration is:\n",
      "[1330]\tTrain's l2: 0.0629847\tTest's l2: 0.11819\n",
      "\n",
      "第2折 训练和预测 训练MSE 预测MSE\n",
      "------\t 训练MSE\t 0.06298469273663146 \t------\n",
      "------\t 预测MSE\t 0.11818985583464771 \t------\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[600]\tTrain's l2: 0.0890119\tTest's l2: 0.154776\n",
      "[1200]\tTrain's l2: 0.0657527\tTest's l2: 0.145928\n",
      "Early stopping, best iteration is:\n",
      "[1664]\tTrain's l2: 0.0553043\tTest's l2: 0.14504\n",
      "\n",
      "第3折 训练和预测 训练MSE 预测MSE\n",
      "------\t 训练MSE\t 0.055304293204514805 \t------\n",
      "------\t 预测MSE\t 0.14503951195788792 \t------\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[600]\tTrain's l2: 0.0887613\tTest's l2: 0.148789\n",
      "[1200]\tTrain's l2: 0.0652522\tTest's l2: 0.139485\n",
      "Early stopping, best iteration is:\n",
      "[1402]\tTrain's l2: 0.0603963\tTest's l2: 0.138853\n",
      "\n",
      "第4折 训练和预测 训练MSE 预测MSE\n",
      "------\t 训练MSE\t 0.060396261620873734 \t------\n",
      "------\t 预测MSE\t 0.13885346971325618 \t------\n",
      "\n",
      "训练集平均MSE:  0.057333663765693564\n",
      "验证集平均MSE:  0.1338374770439618\n"
     ]
    }
   ],
   "source": [
    "# LGB模型\n",
    "\n",
    "# 5 折交叉验证\n",
    "Folds = 5\n",
    "kf = KFold(n_splits = 5, random_state = 0, shuffle = True)\n",
    "# 记录训练和预测MSE\n",
    "MSE_DICT = {\n",
    "    'train_mse': [],\n",
    "    'val_mse': [],\n",
    "}\n",
    "\n",
    "# 线下训练预测\n",
    "for i, (train_index, val_index) in enumerate(kf.split(train)):\n",
    "    lgb_reg = lgb.LGBMRegressor(\n",
    "        boosting_type = 'gbdt',\n",
    "        objective = 'regression',\n",
    "        metric = 'mse',\n",
    "        train_metric = True,\n",
    "        n_estimators = 3000,\n",
    "        early_stopping_rounds = 100,\n",
    "        n_jobs = -1,\n",
    "        learning_rate = 0.01,\n",
    "        max_depth = 4,\n",
    "        feature_fraction = 0.9,\n",
    "        feature_fraction_seed = 0,\n",
    "        bagging_fraction = 0.9, \n",
    "        bagging_freq = 2,\n",
    "        bagging_seed = 0,\n",
    "        lambda_l1 = 1,\n",
    "        lambda_l2 = 1,\n",
    "        verbosity = 1\n",
    "    )\n",
    "\n",
    "    # 切分训练集和测试集\n",
    "    X_train_kf, X_val_kf = train.values[train_index], train.values[val_index]\n",
    "    y_train_kf, y_val_kf = target[train_index], target[val_index]\n",
    "\n",
    "    # 训练模型\n",
    "    lgb_reg.fit(X_train_kf, y_train_kf,\n",
    "                eval_set = [(X_train_kf, y_train_kf), (X_val_kf, y_val_kf)], \n",
    "                eval_names = ['Train', 'Test'], eval_metric = 'mse',\n",
    "                verbose = 600)\n",
    "    # 训练集和验证集预测\n",
    "    y_train_kf_predict = lgb_reg.predict(X_train_kf, num_iteration = lgb_reg.best_iteration_)\n",
    "    y_val_kf_predict = lgb_reg.predict(X_val_kf, num_iteration = lgb_reg.best_iteration_) \n",
    "    \n",
    "    print('\\n第{}折 训练和预测 训练MSE 预测MSE'.format(i))\n",
    "    train_mse = mean_squared_error(y_train_kf_predict, y_train_kf)\n",
    "    print('------\\t', '训练MSE\\t', train_mse, '\\t------')\n",
    "    val_mse = mean_squared_error(y_val_kf_predict, y_val_kf)\n",
    "    print('------\\t', '预测MSE\\t', val_mse, '\\t------\\n')\n",
    "\n",
    "    MSE_DICT['train_mse'].append(train_mse)\n",
    "    MSE_DICT['val_mse'].append(val_mse)\n",
    "\n",
    "print('训练集平均MSE: ', np.mean(MSE_DICT['train_mse']))\n",
    "print('验证集平均MSE: ', np.mean(MSE_DICT['val_mse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}